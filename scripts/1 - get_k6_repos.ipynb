{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /home/samuel/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages (2.3.3)\n",
            "Requirement already satisfied: requests in /home/samuel/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages (2.32.5)\n",
            "Requirement already satisfied: dotenv in /home/samuel/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages (0.9.9)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /home/samuel/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages (from pandas) (2.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/samuel/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/samuel/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/samuel/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/samuel/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/samuel/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/samuel/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/samuel/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages (from requests) (2025.11.12)\n",
            "Requirement already satisfied: python-dotenv in /home/samuel/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages (from dotenv) (1.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /home/samuel/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas requests dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')\n",
        "\n",
        "if not GITHUB_TOKEN:\n",
        "    raise RuntimeError(\"GITHUB_TOKEN não encontrado no .env. Adicione uma linha: GITHUB_TOKEN=seu_token\")\n",
        "\n",
        "HEADERS = {'Authorization': f'token {GITHUB_TOKEN}'}\n",
        "\n",
        "QUERY = r'/import\\s+(?:\\w+|\\* as\\s*\\w+|\\{[^}]+\\})\\s+from\\s+[\\'\"`]k6[^\\'\"`]*[\\'\"`]/' + ' AND (language:JavaScript OR language:TypeScript) '"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gerar CSV pra usar na analise dos repositorios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdxvapkcKjsE",
        "outputId": "0011a504-328f-4dbd-d479-5f4271970b79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Buscando página 1 com query: /import\\s+(?:\\w+|\\* as\\s*\\w+|\\{[^}]+\\})\\s+from\\s+[\\'\"`]k6[^\\'\"`]*[\\'\"`]/ AND (language:JavaScript OR language:TypeScript) \n",
            "Status code: 422\n",
            "Erro 422 (Unprocessable Entity) na página 1. Isso geralmente indica que o limite de 1000 resultados da API de busca do GitHub foi atingido ou a consulta é inválida. Encerrando busca.\n",
            "Total de repositórios encontrados: 0\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import csv\n",
        "import time\n",
        "\n",
        "# Função para buscar repositórios, agora com debug e URL encoding\n",
        "def buscar_repositorios(paginas=5, query = QUERY):\n",
        "    repositorios = {}\n",
        "    url = 'https://api.github.com/search/code'\n",
        "\n",
        "    for page in range(1, paginas + 1):\n",
        "        params = {'q': query, 'per_page': 100, 'page': page}\n",
        "        print(f'Buscando página {page} com query: {params[\"q\"]}')  # DEBUG\n",
        "        response = requests.get(url, headers=HEADERS, params=params)\n",
        "        print(f'Status code: {response.status_code}')  # DEBUG\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            if 'items' not in data or len(data['items']) == 0:\n",
        "                print(f'Nenhum resultado encontrado na página {page}. Encerrando busca.')\n",
        "                break\n",
        "            for item in data['items']:\n",
        "                repo_name = item['repository']['full_name']\n",
        "                repo_url = item['repository']['html_url']\n",
        "                file_path = item['path']\n",
        "                if repo_name not in repositorios:\n",
        "                    repositorios[repo_name] = {'url': repo_url, 'arquivos': []}\n",
        "                repositorios[repo_name]['arquivos'].append(file_path)\n",
        "        elif response.status_code == 403:\n",
        "            print(f'Limite de taxa atingido. Aguardando 60 segundos.')\n",
        "            time.sleep(60)\n",
        "            page -= 1  # Retry current page\n",
        "            continue\n",
        "        elif response.status_code == 422:\n",
        "            print(f'Erro 422 (Unprocessable Entity) na página {page}. Isso geralmente indica que o limite de 1000 resultados da API de busca do GitHub foi atingido ou a consulta é inválida. Encerrando busca.')\n",
        "            break  # Stop if we hit this error\n",
        "        else:\n",
        "            print(f'Erro inesperado na requisição na página {page}: {response.status_code}. Encerrando busca.')\n",
        "            break\n",
        "\n",
        "    return repositorios\n",
        "\n",
        "# Função para salvar CSV permanece igual\n",
        "def salvar_csv(repositorios, arquivo_saida='repositorios_k6.csv'):\n",
        "    with open(arquivo_saida, mode='w', newline='', encoding='utf-8') as csv_file:\n",
        "        fieldnames = ['repositório', 'url', 'arquivos']\n",
        "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for repo_name, info in repositorios.items():\n",
        "            writer.writerow({'repositório': repo_name, 'url': info['url'], 'arquivos': '; '.join(info['arquivos'])})\n",
        "    print(f'Resultados salvos em {arquivo_saida}')\n",
        "\n",
        "\n",
        "repositorios = buscar_repositorios(paginas=5)\n",
        "print(f'Total de repositórios encontrados: {len(repositorios)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Buscando página 1 com query: import \"k6\" OR import 'k6' language:JavaScript OR language:TypeScriptrepo:HariSekhon/Templates\n",
            "Status code: 403\n",
            "Limite de taxa atingido. Aguardando 60 segundos.\n",
            "Status code: 403\n",
            "Limite de taxa atingido. Aguardando 60 segundos.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m names = repositorios.keys()\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m names:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     files = \u001b[43mbuscar_repositorios\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaginas\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mQUERY\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrepo:\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m+\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(files)\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mbuscar_repositorios\u001b[39m\u001b[34m(paginas, query)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m403\u001b[39m:\n\u001b[32m     29\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mLimite de taxa atingido. Aguardando 60 segundos.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     page -= \u001b[32m1\u001b[39m  \u001b[38;5;66;03m# Retry current page\u001b[39;00m\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "names = repositorios.keys()\n",
        "for name in names:\n",
        "    files = buscar_repositorios(paginas=5, query=QUERY + ' repo:'+name)\n",
        "    print(files)\n",
        "    break\n",
        "# names = repositorios['repositório']\n",
        "# names.head()\n",
        "# salvar_csv(repositorios, 'output/repositorios_k6.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Função: procurar arquivos k6 adicionais no repositório usando a API de trees do GitHub\n",
        "import os\n",
        "import re\n",
        "\n",
        "def find_additional_k6_scripts(repo_full_name, known_files_list):\n",
        "    \"\"\"Retorna lista de caminhos de arquivos que parecem scripts k6 e que não estão\n",
        "    presentes em `known_files_list` (lista de strings). Usa a API /git/trees/{branch}?recursive=1\n",
        "    e inspeciona o conteúdo dos blobs procurando por `import 'k6'`, `import \"k6\"`, `from 'k6'`,\n",
        "    `require('k6')` etc., seguindo a mesma estratégia da célula de busca global (celula 4),\n",
        "    mas limitada ao repositório fornecido.\n",
        "    \"\"\"\n",
        "    details = get_repo_details(repo_full_name)\n",
        "    if not details:\n",
        "        return []\n",
        "    owner, repo = repo_full_name.split('/')\n",
        "    branch = details.get('default_branch') or 'main'\n",
        "    url = f'https://api.github.com/repos/{owner}/{repo}/git/trees/{branch}?recursive=1'\n",
        "    tree_data = make_github_api_request(url)\n",
        "    if not tree_data or 'tree' not in tree_data:\n",
        "        return []\n",
        "\n",
        "    # padrão para detectar import/require do k6 (simples e robusto)\n",
        "    pattern = re.compile(r\"(?:import\\s+(?:.*\\s+from\\s+)?['\\\"]k6['\\\"])|(?:require\\(\\s*['\\\"]k6['\\\"]\\s*\\))\", re.IGNORECASE)\n",
        "\n",
        "    # normalizar known files (lista contém strings possivelmente separadas por ';')\n",
        "    known_set = set()\n",
        "    for entry in known_files_list or []:\n",
        "        if not isinstance(entry, str):\n",
        "            continue\n",
        "        for part in [p.strip() for p in entry.split(';') if p.strip()]:\n",
        "            known_set.add(part)\n",
        "\n",
        "    candidates = []\n",
        "\n",
        "    # Percorrer a árvore e inspecionar arquivos .js/.ts\n",
        "    for item in tree_data['tree']:\n",
        "        if item.get('type') != 'blob':\n",
        "            continue\n",
        "        path = item.get('path')\n",
        "        if not path:\n",
        "            continue\n",
        "        lower = path.lower()\n",
        "        if not lower.endswith(('.js', '.ts')):\n",
        "            continue\n",
        "\n",
        "        # Buscar o conteúdo do blob via SHA (usa get_file_content which já faz base64 decode)\n",
        "        sha = item.get('sha')\n",
        "        if not sha:\n",
        "            continue\n",
        "        try:\n",
        "            content = get_file_content(repo_full_name, sha)\n",
        "        except Exception as e:\n",
        "            # proteger contra falhas pontuais na API\n",
        "            print(f\"Erro ao buscar conteúdo de {repo_full_name}:{path} -> {e}\")\n",
        "            content = None\n",
        "        if not content:\n",
        "            continue\n",
        "\n",
        "        # Checar se o arquivo importa/require o k6\n",
        "        if pattern.search(content):\n",
        "            candidates.append(path)\n",
        "\n",
        "    # remover conhecidos e retornar ordenado\n",
        "    new_files = sorted([c for c in set(candidates) if c not in known_set])\n",
        "    return new_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Backup do CSV original salvo em: output/repositorios_k6.csv.bak\n",
            "Error decoding base64 content for SHA 6704b30c2100f21d386a9b6c525a85717e144eb5 in HariSekhon/Templates: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 6704b30c2100f21d386a9b6c525a85717e144eb5 in HariSekhon/Templates: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 73bb569fb6cdd822950fc9fd1947a977c92b0577 in HariSekhon/Templates: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 73bb569fb6cdd822950fc9fd1947a977c92b0577 in HariSekhon/Templates: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 4b1425fd4e398b85e0b098990d21e27a38450342 in HariSekhon/Templates: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 4b1425fd4e398b85e0b098990d21e27a38450342 in HariSekhon/Templates: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 5172ed7fedae8b015d7b4fa56e38281fef539012 in grafana/setup-k6-action: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 5172ed7fedae8b015d7b4fa56e38281fef539012 in grafana/setup-k6-action: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA fba3c57a80c662c2e5aaa0f538dd3d6ed8830dd1 in grafana/setup-k6-action: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA fba3c57a80c662c2e5aaa0f538dd3d6ed8830dd1 in grafana/setup-k6-action: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA f5e30ea9ae4994e7f30c2503f6dac5707c3b987d in grafana/setup-k6-action: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA f5e30ea9ae4994e7f30c2503f6dac5707c3b987d in grafana/setup-k6-action: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA ce12460adf7894b53e9e0941b2f041319e850fba in grafana/setup-k6-action: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA ce12460adf7894b53e9e0941b2f041319e850fba in grafana/setup-k6-action: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 80326af5b33bf0ebe86b3532b625bcc56a51aadd in grafana/setup-k6-action: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 80326af5b33bf0ebe86b3532b625bcc56a51aadd in grafana/setup-k6-action: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 87527d5bd917d9a44fdd97151c5ed10d08afc6f0 in grafana/setup-k6-action: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 87527d5bd917d9a44fdd97151c5ed10d08afc6f0 in grafana/setup-k6-action: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 82340a18bca46a8c061e772f695980de79617e07 in grafana/setup-k6-action: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 82340a18bca46a8c061e772f695980de79617e07 in grafana/setup-k6-action: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA e9c809eff4dcfbab394c205f26474b69809e4863 in gzydong/go-chat: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA e9c809eff4dcfbab394c205f26474b69809e4863 in gzydong/go-chat: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 3f770a93abcc4485023a2e09f546d623ba50a5a6 in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 3f770a93abcc4485023a2e09f546d623ba50a5a6 in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 226c02532fefa75d7209d1204fddf0e9acbe00b5 in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 226c02532fefa75d7209d1204fddf0e9acbe00b5 in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 98552f2c4901fd6463e9e78c12ac107b282ac187 in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 98552f2c4901fd6463e9e78c12ac107b282ac187 in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 3f5b523eb062d7eae1f94c4ba5f735c78d243f7a in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 3f5b523eb062d7eae1f94c4ba5f735c78d243f7a in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 7d431a685cc637f7a3ba351eea1c365100f8ed0d in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 7d431a685cc637f7a3ba351eea1c365100f8ed0d in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA d2387058320df1454126d227ee6c3b200aa6ddb8 in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA d2387058320df1454126d227ee6c3b200aa6ddb8 in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 1b990fb7a52a220550ceac528d575ad9967e16a0 in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 1b990fb7a52a220550ceac528d575ad9967e16a0 in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA ed69dcdcfeeb6644c308b0d43e00a64514a3c8be in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA ed69dcdcfeeb6644c308b0d43e00a64514a3c8be in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA b0b3f2c8985f7cc6d2a4cc7479cdcb876cecdc81 in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA b0b3f2c8985f7cc6d2a4cc7479cdcb876cecdc81 in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA f00098b85a9a7016f884dec2f599512993ccf327 in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA f00098b85a9a7016f884dec2f599512993ccf327 in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 6581b97ff4bd4dab4530c79f032e7cf4e2075784 in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 6581b97ff4bd4dab4530c79f032e7cf4e2075784 in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 62cc7f3bac08f57db392995958555523759b8acc in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 62cc7f3bac08f57db392995958555523759b8acc in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA b4a975892f14f4b8e1acee0a9f6168c90258fd53 in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA b4a975892f14f4b8e1acee0a9f6168c90258fd53 in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 1280ea5147bdc9755ae94c4c04368eb31cace95b in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 1280ea5147bdc9755ae94c4c04368eb31cace95b in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 90e8f1412b41169db054feb910ab65b665f0f6af in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 90e8f1412b41169db054feb910ab65b665f0f6af in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA f7ceb3d1051a1c07d2af766d5a5582654666a81a in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA f7ceb3d1051a1c07d2af766d5a5582654666a81a in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 95c1ea8a4b6e88b70a634c52173df86c8ff92b42 in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n",
            "Error decoding base64 content for SHA 95c1ea8a4b6e88b70a634c52173df86c8ff92b42 in hari-p8-io/RestVsGrpc: name 'base64' is not defined. Skipping.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m repo, known \u001b[38;5;129;01min\u001b[39;00m repo_known.items():\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m         new = \u001b[43mfind_additional_k6_scripts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mknown\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     35\u001b[39m         new = [\u001b[33m'\u001b[39m\u001b[33merror: \u001b[39m\u001b[33m'\u001b[39m + \u001b[38;5;28mstr\u001b[39m(e)]\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mfind_additional_k6_scripts\u001b[39m\u001b[34m(repo_full_name, known_files_list)\u001b[39m\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     content = \u001b[43mget_file_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_full_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     53\u001b[39m     \u001b[38;5;66;03m# proteger contra falhas pontuais na API\u001b[39;00m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mErro ao buscar conteúdo de \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_full_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mget_file_content\u001b[39m\u001b[34m(repo_full_name, file_sha)\u001b[39m\n\u001b[32m      2\u001b[39m owner, repo = repo_full_name.split(\u001b[33m'\u001b[39m\u001b[33m/\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m url = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://api.github.com/repos/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mowner\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/git/blobs/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_sha\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m blob_data = \u001b[43mmake_github_api_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m blob_data:\n\u001b[32m      8\u001b[39m     content_encoding = blob_data.get(\u001b[33m'\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mmake_github_api_request\u001b[39m\u001b[34m(url, params, max_retries)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m retry_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_retries):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m         response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mHEADERS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m200\u001b[39m:\n\u001b[32m      6\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m response.json()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages/requests/api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages/requests/adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages/urllib3/connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    568\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.14/http/client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.14/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.14/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.14/socket.py:725\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    723\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    724\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m725\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    727\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.14/ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.14/ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Exemplo de uso: verificar todos os repositórios, detectar arquivos que importam/require k6\n",
        "# e atualizar o CSV existente (`repositorios_k6.csv`) adicionando os novos caminhos no campo 'arquivos'.\n",
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "csv_path = 'output/repositorios_k6.csv'\n",
        "alt = os.path.join('scripts','repositorios_k6.csv')\n",
        "if not os.path.exists(csv_path) and os.path.exists(alt):\n",
        "    csv_path = alt\n",
        "\n",
        "# Fazer backup do CSV original antes de modificar\n",
        "if os.path.exists(csv_path):\n",
        "    backup_path = csv_path + '.bak'\n",
        "    shutil.copyfile(csv_path, backup_path)\n",
        "    print(f'Backup do CSV original salvo em: {backup_path}')\n",
        "\n",
        "# Ler CSV existente\n",
        "df_repos = pd.read_csv(csv_path)\n",
        "# Garantir colunas esperadas\n",
        "if 'arquivos' not in df_repos.columns:\n",
        "    df_repos['arquivos'] = ''\n",
        "\n",
        "# Construir mapa repo -> arquivos conhecidos (string de entradas separadas por ';')\n",
        "repo_known = {}\n",
        "for _, r in df_repos.iterrows():\n",
        "    repo_name = r['repositório']\n",
        "    repo_known[repo_name] = r.get('arquivos', '') if 'arquivos' in r else ''\n",
        "\n",
        "results = []\n",
        "\n",
        "for repo, known in repo_known.items():\n",
        "    try:\n",
        "        new = find_additional_k6_scripts(repo, [known])\n",
        "    except Exception as e:\n",
        "        new = ['error: ' + str(e)]\n",
        "    if new:\n",
        "        # registrar para arquivo adicional e também atualizar o DataFrame\n",
        "        results.append({'repositório': repo, 'novos_arquivos': '; '.join(new)})\n",
        "        print(f'{repo}: {len(new)} novos arquivo(s) detectado(s)')\n",
        "\n",
        "        # Atualizar a linha do DataFrame (concatenar sem duplicatas)\n",
        "        idx = df_repos.index[df_repos['repositório'] == repo]\n",
        "        if len(idx) > 0:\n",
        "            i = idx[0]\n",
        "            existing = df_repos.at[i, 'arquivos'] if pd.notna(df_repos.at[i, 'arquivos']) else ''\n",
        "            existing_set = set([p.strip() for p in existing.split(';') if p.strip()])\n",
        "            for nf in new:\n",
        "                existing_set.add(nf)\n",
        "            df_repos.at[i, 'arquivos'] = '; '.join(sorted(existing_set))\n",
        "        else:\n",
        "            # caso improvável: repositório não exista no CSV, adicionar nova linha\n",
        "            df_repos = df_repos.append({\n",
        "                'repositório': repo,\n",
        "                'url': '',\n",
        "                'arquivos': '; '.join(new)\n",
        "            }, ignore_index=True)\n",
        "\n",
        "# Salvar CSV atualizado (sobrescreve o original)\n",
        "if not results:\n",
        "    print('Nenhum arquivo adicional detectado.')\n",
        "else:\n",
        "    df_repos.to_csv(csv_path, index=False)\n",
        "    pd.DataFrame(results).to_csv('additional_k6_files.csv', index=False)\n",
        "    print(f'Salvo {len(results)} entradas em additional_k6_files.csv e atualizado {csv_path}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gerar o CSV pra uso no TCC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b9702ea8"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import base64\n",
        "import requests\n",
        "import csv\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Funções auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac8bb086",
        "outputId": "60951df3-e56a-45ec-c93b-005b30270ed9"
      },
      "outputs": [],
      "source": [
        "def make_github_api_request(url, params=None, max_retries=5):\n",
        "    for retry_num in range(max_retries):\n",
        "        try:\n",
        "            response = requests.get(url, headers=HEADERS, params=params)\n",
        "            if response.status_code == 200:\n",
        "                return response.json()\n",
        "            elif response.status_code == 403:\n",
        "                print(f\"Rate limit exceeded. Waiting 60 seconds. Retries left: {max_retries - 1 - retry_num}\")\n",
        "                time.sleep(60)\n",
        "            elif response.status_code == 404:\n",
        "                print(f\"Resource not found at {url}. Skipping.\")\n",
        "                return None\n",
        "            else:\n",
        "                print(f\"Error making request to {url}: Status code {response.status_code}, Response: {response.text}\")\n",
        "                return None\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Request failed: {e}. Retries left: {max_retries - 1 - retry_num}\")\n",
        "            time.sleep(5) # Shorter wait for network errors\n",
        "    print(f\"Failed to make request to {url} after {max_retries} retries.\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9fe5338",
        "outputId": "38c28647-e1c1-44e9-ef6b-a09b309df7e4"
      },
      "outputs": [],
      "source": [
        "def get_repo_details(repo_full_name):\n",
        "    owner, repo = repo_full_name.split('/')\n",
        "    url = f'https://api.github.com/repos/{owner}/{repo}'\n",
        "    repo_data = make_github_api_request(url)\n",
        "    if repo_data:\n",
        "        return {\n",
        "            'default_branch': repo_data.get('default_branch'),\n",
        "            'stargazers_count': repo_data.get('stargazers_count')\n",
        "        }\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6ecbcda",
        "outputId": "9dec8261-8660-497a-b7dc-b539cac8a298"
      },
      "outputs": [],
      "source": [
        "def get_file_tree(repo_full_name, sha):\n",
        "    owner, repo = repo_full_name.split('/')\n",
        "    url = f'https://api.github.com/repos/{owner}/{repo}/git/trees/{sha}?recursive=1'\n",
        "    tree_data = make_github_api_request(url)\n",
        "    if tree_data and 'tree' in tree_data:\n",
        "        non_markdown_files = []\n",
        "        markdown_extensions = ('.md', '.markdown')\n",
        "        for item in tree_data['tree']:\n",
        "            # Return path and sha for non-markdown blob files\n",
        "            if item['type'] == 'blob' and not item['path'].lower().endswith(markdown_extensions):\n",
        "                non_markdown_files.append({'path': item['path'], 'sha': item['sha']})\n",
        "        return non_markdown_files\n",
        "    return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40158aff",
        "outputId": "10036c3f-fdb6-4ec8-c268-0b6d2e1241da"
      },
      "outputs": [],
      "source": [
        "def get_file_content(repo_full_name, file_sha):\n",
        "    owner, repo = repo_full_name.split('/')\n",
        "    url = f'https://api.github.com/repos/{owner}/{repo}/git/blobs/{file_sha}'\n",
        "\n",
        "    blob_data = make_github_api_request(url)\n",
        "\n",
        "    if blob_data:\n",
        "        content_encoding = blob_data.get('encoding')\n",
        "        content_data = blob_data.get('content')\n",
        "\n",
        "        if content_data is None:\n",
        "            print(f\"No content data found for SHA {file_sha} in {repo_full_name}. Skipping.\")\n",
        "            return None\n",
        "\n",
        "        if content_encoding == 'base64':\n",
        "            try:\n",
        "                # Base64 decode, then try UTF-8 decode\n",
        "                decoded_bytes = base64.b64decode(content_data)\n",
        "                decoded_content = decoded_bytes.decode('utf-8')\n",
        "                return decoded_content\n",
        "            except UnicodeDecodeError:\n",
        "                print(f\"UnicodeDecodeError for SHA {file_sha} in {repo_full_name}. Content appears binary or non-UTF8. Skipping.\")\n",
        "                return None\n",
        "            except Exception as e:\n",
        "                print(f\"Error decoding base64 content for SHA {file_sha} in {repo_full_name}: {e}. Skipping.\")\n",
        "                return None\n",
        "        elif content_encoding == 'utf-8':\n",
        "            # Content is already UTF-8 encoded string\n",
        "            return content_data\n",
        "        else:\n",
        "            print(f\"Unknown or unsupported encoding '{content_encoding}' for SHA {file_sha} in {repo_full_name}. Skipping.\")\n",
        "            return None\n",
        "    elif blob_data is None:\n",
        "        # make_github_api_request already printed error/skip message\n",
        "        return None\n",
        "    else:\n",
        "        print(f\"Could not get blob data for SHA {file_sha} in {repo_full_name}. Skipping.\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31f33101",
        "outputId": "5339ff7a-5932-4ef4-8dea-91a106f4a6bc"
      },
      "outputs": [],
      "source": [
        "def count_lines_of_code(content):\n",
        "    if content is None:\n",
        "        return 0\n",
        "    return len(content.splitlines())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Obter os dados e salvar no csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6333a52",
        "outputId": "5663ba4d-83c0-4071-c0f6-89243152fce6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(442, 3)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_repos = pd.read_csv('repositorios_k6.csv')\n",
        "unique_repos = df_repos[['repositório', 'url']].drop_duplicates().to_dict('records')\n",
        "df_repos.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a184117",
        "outputId": "fb5966ed-947b-47c2-c97f-7eaa95fb83cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting parallel processing of 442 repositories with 8 workers...\n",
            "processed adko99/loadtesting\n",
            "processed adko99/loadtesting\n",
            "processed grafana/k6-jslib-aws\n",
            "processed hari-p8-io/RestVsGrpc\n",
            "processed HariSekhon/Templates\n",
            "processed grafana/k6-jslib-aws\n",
            "processed hari-p8-io/RestVsGrpc\n",
            "processed HariSekhon/Templates\n",
            "processed grafana/setup-k6-action\n",
            "processed grafana/setup-k6-action\n",
            "processed urykhy/stuff\n",
            "processed urykhy/stuff\n",
            "processed matt-churcher/k6\n",
            "processed tais-santos-silva/k6\n",
            "processed m8/cpp_rest\n",
            "processed matt-churcher/k6\n",
            "processed tais-santos-silva/k6\n",
            "processed m8/cpp_rest\n",
            "processed frankmendonca/k6-poc\n",
            "processed frankmendonca/k6-poc\n",
            "processed ycchuang99/opentelemetry-laravel-apm\n",
            "processed ycchuang99/opentelemetry-laravel-apm\n",
            "processed Henriquedev0/K6_project\n",
            "processed Henriquedev0/K6_project\n",
            "processed SheikhSuhail19/Grafana-k6-Learning\n",
            "processed SheikhSuhail19/Grafana-k6-Learning\n",
            "processed tus/load-tester\n",
            "processed tus/load-tester\n",
            "processed vfarcic/k6-demo\n",
            "processed vfarcic/k6-demo\n",
            "processed localstack-samples/serverless-data-processing-pipeline\n",
            "processed chan4lk/k6-browser-perf-tests\n",
            "processed localstack-samples/serverless-data-processing-pipeline\n",
            "processed chan4lk/k6-browser-perf-tests\n",
            "processed Leonchik14/AnonymousChat\n",
            "processed Leonchik14/AnonymousChat\n",
            "processed Astrotomic/opendor.me\n",
            "processed Astrotomic/opendor.me\n",
            "processed go-sigma/sigma\n",
            "processed go-sigma/sigma\n",
            "processed skursatToklucu/LoadProbe\n",
            "processed skursatToklucu/LoadProbe\n",
            "processed MattPChoy/MicroserviceArchitecture\n",
            "processed MattPChoy/MicroserviceArchitecture\n",
            "processed JohnnyKamigashima/PGATS-k6\n",
            "processed JohnnyKamigashima/PGATS-k6\n",
            "processed 6-BARK/neighborhood\n",
            "processed 6-BARK/neighborhood\n",
            "processed Zhao-Hansi/K6-test-demo\n",
            "processed Zhao-Hansi/K6-test-demo\n",
            "processed danthegoodman1/EpicEpoch\n",
            "processed danthegoodman1/EpicEpoch\n",
            "processed parthmern/backendLoadTesting-K6\n",
            "processed parthmern/backendLoadTesting-K6\n",
            "processed SumanReddy568/cheatcode\n",
            "processed SumanReddy568/cheatcode\n",
            "processed kotoant/spring-petclinic-rest\n",
            "processed furkannzmnn/k6-load-test\n",
            "processed kotoant/spring-petclinic-rest\n",
            "processed furkannzmnn/k6-load-test\n",
            "processed hoyirul/laravel9-starter-stisla\n",
            "processed hoyirul/laravel9-starter-stisla\n",
            "processed gino79445/Canchu\n",
            "processed gino79445/Canchu\n",
            "processed epomatti/aks-autoscaler-metrics\n",
            "processed epomatti/aks-autoscaler-metrics\n",
            "processed ifpebj-ti/Modulo_Frontend-CRM\n",
            "processed ifpebj-ti/Modulo_Frontend-CRM\n",
            "processed shamir92/project-sprint-team-happy\n",
            "processed shamir92/project-sprint-team-happy\n",
            "processed MilanDean/cloud-distilBERT-MLsystems\n",
            "processed MilanDean/cloud-distilBERT-MLsystems\n",
            "processed 7etrahedral/k6-script\n",
            "processed 7etrahedral/k6-script\n",
            "processed programadriano/k6-loadtest-net6-heroku\n",
            "processed programadriano/k6-loadtest-net6-heroku\n",
            "processed Prakash-Achanta/k6-test\n",
            "processed Prakash-Achanta/k6-test\n",
            "processed prastamaha/envelope-encryption-example\n",
            "processed prastamaha/envelope-encryption-example\n",
            "processed hauzanrafiattallah/spring-redis-compare\n",
            "processed hauzanrafiattallah/spring-redis-compare\n",
            "processed hakimamarullah/docker-kingdom\n",
            "processed hakimamarullah/docker-kingdom\n",
            "processed tadeifelipe/e_wallet\n",
            "processed tadeifelipe/e_wallet\n",
            "processed Rilok21/k6-with-grafana\n",
            "processed Rilok21/k6-with-grafana\n",
            "processed claudioStahl/kafka_sync\n",
            "processed claudioStahl/kafka_sync\n",
            "processed Cmdmdz/script-k6\n",
            "processed Cmdmdz/script-k6\n",
            "processed userwhoga/midka\n",
            "processed userwhoga/midka\n",
            "processed rpp36-sdc-utf8/rpp36-aaron-overview\n",
            "processed rpp36-sdc-utf8/rpp36-aaron-overview\n",
            "processed cluesurf/tone\n",
            "processed cluesurf/tone\n",
            "processed Chris-Owusu/k6\n",
            "processed Chris-Owusu/k6\n",
            "processed amir3ash/chatt\n",
            "processed yosilia/ecommerce-full-site\n",
            "processed amir3ash/chatt\n",
            "processed yosilia/ecommerce-full-site\n",
            "processed 2024-Hanium-PlanDing/PlanDing-Backend\n",
            "processed CoCreate-app/CoCreate-loadtest\n",
            "processed feejunior/k6login\n",
            "processed 2024-Hanium-PlanDing/PlanDing-Backend\n",
            "processed CoCreate-app/CoCreate-loadtest\n",
            "processed feejunior/k6login\n",
            "processed Qubicon/QuickLink-TSS\n",
            "processed Qubicon/QuickLink-TSS\n",
            "processed JamesGrant1811/k6-udemy\n",
            "processed Magnificent-Malasada/ratingsAndReviews\n",
            "processed JamesGrant1811/k6-udemy\n",
            "processed Magnificent-Malasada/ratingsAndReviews\n",
            "processed Galactic-Empire-SDC/Products\n",
            "processed Galactic-Empire-SDC/Products\n",
            "processed Anawataon/tools-k6\n",
            "processed Anawataon/tools-k6\n",
            "processed Gun-1/k6-proj-github\n",
            "processed matfritzen/k6-tests\n",
            "processed Gun-1/k6-proj-github\n",
            "processed matfritzen/k6-tests\n",
            "processed berenteb/ticketpond-backend-nx\n",
            "processed berenteb/ticketpond-backend-nx\n",
            "processed MarcinAman/url-shortener\n",
            "processed ranggaadithia/sora-load-test\n",
            "processed MarcinAman/url-shortener\n",
            "processed ranggaadithia/sora-load-test\n",
            "processed JoakimJohesan/k6-load-testing\n",
            "processed JoakimJohesan/k6-load-testing\n",
            "processed Ansh-Sarkar/k8s-loki-evals\n",
            "processed Ansh-Sarkar/k8s-loki-evals\n",
            "processed luke-h1/analytics-dashboard\n",
            "processed luke-h1/analytics-dashboard\n",
            "processed mrezende1/testes-performance\n",
            "processed mrezende1/testes-performance\n",
            "processed shiskr/k6-sample\n",
            "processed shiskr/k6-sample\n",
            "processed ReStarkov/k6-examples\n",
            "processed ReStarkov/k6-examples\n",
            "processed powerandcontrol/Simula-o-Teste-de-Carga-PI2-2025-01-\n",
            "processed kwe/Great-Api-Challenge-2\n",
            "processed powerandcontrol/Simula-o-Teste-de-Carga-PI2-2025-01-\n",
            "processed kwe/Great-Api-Challenge-2\n",
            "processed aldrincartago/k6-performance-testing\n",
            "processed aldrincartago/k6-performance-testing\n",
            "processed Gurusharan-Singh2/cfBackend\n",
            "processed Gurusharan-Singh2/cfBackend\n",
            "processed dudapierri/Performance-tests-k6\n",
            "processed dudapierri/Performance-tests-k6\n",
            "processed Junrapxng/k6-dashboard\n",
            "processed dunghcmut/BEne\n",
            "processed Junrapxng/k6-dashboard\n",
            "processed dunghcmut/BEne\n",
            "processed tariqazmat101/k6-websockets-testing\n",
            "processed tariqazmat101/k6-websockets-testing\n",
            "processed hazelcast-guides/spring-hazelcast-pipeline-dispatcher\n",
            "processed hazelcast-guides/spring-hazelcast-pipeline-dispatcher\n",
            "processed maxoliverbr/k6GithubActions\n",
            "processed maxoliverbr/k6GithubActions\n",
            "processed AbidKhairyAK/learn-k6\n",
            "processed AbidKhairyAK/learn-k6\n",
            "processed rony431/willdom\n",
            "processed rony431/willdom\n",
            "processed armydep/shorten-url\n",
            "processed armydep/shorten-url\n",
            "processed norizi/K6-Laravel\n",
            "processed norizi/K6-Laravel\n",
            "processed Ajayan-NTP/hotelApp\n",
            "processed Ajayan-NTP/hotelApp\n",
            "processed djesusnet/Cursok6\n",
            "processed djesusnet/Cursok6\n",
            "processed asindarov/Future-me-clone\n",
            "processed asindarov/Future-me-clone\n",
            "processed themisterbondy/postech-tech-challenge\n",
            "processed themisterbondy/postech-tech-challenge\n",
            "processed alfnsnff/eticket-api\n",
            "processed alfnsnff/eticket-api\n",
            "processed CintyaAprilaFandini/PPL_KUIS-1\n",
            "processed mateusoliveiraps/k6_estudos\n",
            "processed CintyaAprilaFandini/PPL_KUIS-1\n",
            "processed mateusoliveiraps/k6_estudos\n",
            "processed siweh/LumaWebAppTesting\n",
            "processed siweh/LumaWebAppTesting\n",
            "processed kritozemu/cblog\n",
            "processed kritozemu/cblog\n",
            "processed marinagiaquinto/k6\n",
            "processed marinagiaquinto/k6\n",
            "processed msouza009/curso-k6\n",
            "processed msouza009/curso-k6\n",
            "processed rxtcp/dissertation-on-measuring-system-performance-indicators\n",
            "processed rxtcp/dissertation-on-measuring-system-performance-indicators\n",
            "processed hsiungc/ml_api\n",
            "processed hsiungc/ml_api\n",
            "processed jhsmith22/w255-finalproject\n",
            "processed jhsmith22/w255-finalproject\n",
            "processed vhr1975/datasciw255\n",
            "processed vhr1975/datasciw255\n",
            "processed nandanugg/HaloSusterTestCasesPSW3B2\n",
            "processed hakimamarullah/transaction-service-sp\n",
            "processed nandanugg/HaloSusterTestCasesPSW3B2\n",
            "processed hakimamarullah/transaction-service-sp\n",
            "processed dina2203/rkJava\n",
            "processed dina2203/rkJava\n",
            "processed SaifAutomatron/k6\n",
            "processed SaifAutomatron/k6\n",
            "processed trangle-sioux/k6-performance\n",
            "processed trangle-sioux/k6-performance\n",
            "processed ardatan/feTS\n",
            "processed ardatan/feTS\n",
            "processed supabase/benchmarks\n",
            "processed supabase/benchmarks\n",
            "processed supercheck-io/supercheck\n",
            "processed supercheck-io/supercheck\n",
            "processed Oniqq60/project\n",
            "processed Oniqq60/project\n",
            "processed ljvillarrealv/grafanak6\n",
            "processed narender-kumar-asurion/search-poc\n",
            "processed ljvillarrealv/grafanak6\n",
            "processed narender-kumar-asurion/search-poc\n",
            "processed nicolevanderhoeven/k6-scripts\n",
            "processed nicolevanderhoeven/k6-scripts\n",
            "processed tphummel/CaNFlySLO\n",
            "processed tphummel/CaNFlySLO\n",
            "processed MuhammadAqil25/SQAMobbi\n",
            "processed MuhammadAqil25/SQAMobbi\n",
            "processed sehyeogg365/hhplus_ecommerce\n",
            "processed sehyeogg365/hhplus_ecommerce\n",
            "processed aubronsamuel-hash/a\n",
            "processed aubronsamuel-hash/a\n",
            "processed IceScout26/swagger-petstore-sqa\n",
            "processed IceScout26/swagger-petstore-sqa\n",
            "processed nadiaalnd/Performance-Test-Adamlabs-Demo\n",
            "processed nadiaalnd/Performance-Test-Adamlabs-Demo\n",
            "processed up2code/demo-dev-container\n",
            "processed up2code/demo-dev-container\n",
            "processed 6-BARK/PhotoGallery_Proxy\n",
            "processed 6-BARK/PhotoGallery_Proxy\n",
            "processed rancher/dartboard\n",
            "processed rancher/dartboard\n",
            "processed owncloud/cdperf\n",
            "processed owncloud/cdperf\n",
            "processed sdc-jackson/user-service\n",
            "processed sdc-jackson/user-service\n",
            "processed liweiyuan/students-manager\n",
            "processed liweiyuan/students-manager\n",
            "processed vincentinttsh/2FA-thesis\n",
            "processed vincentinttsh/2FA-thesis\n",
            "processed petechain23/K6\n",
            "processed petechain23/K6\n",
            "processed Ovi/DummyJSON\n",
            "processed Ovi/DummyJSON\n",
            "processed julianshen/yatagarasu\n",
            "processed julianshen/yatagarasu\n",
            "processed ValterIversen/valteriversen\n",
            "processed ValterIversen/valteriversen\n",
            "processed srperf/k6Modular\n",
            "processed srperf/k6Modular\n",
            "processed fuji-184/FNode_HTTP\n",
            "processed fuji-184/FNode_HTTP\n",
            "processed frevar1975/Clases\n",
            "processed frevar1975/Clases\n",
            "processed LauroDF/FinalChallenge\n",
            "processed LauroDF/FinalChallenge\n",
            "processed timpamungkasudemy/ai-assisted-testing-k6\n",
            "processed timpamungkasudemy/ai-assisted-testing-k6\n",
            "processed HugoBouttes/poc-queen-mongodb\n",
            "processed HugoBouttes/poc-queen-mongodb\n",
            "processed vifor/faas-to-iaas-migration-framework\n",
            "processed vifor/faas-to-iaas-migration-framework\n",
            "processed MatheusGFritzke/chaos-test\n",
            "processed MatheusGFritzke/chaos-test\n",
            "processed DiogoRibeiro7/git-actions-collection\n",
            "processed DiogoRibeiro7/git-actions-collection\n",
            "processed Interstellarss/faas-share-test\n",
            "processed Interstellarss/faas-share-test\n",
            "processed mulyosyahidin/spring-boot-vocasia-microservices\n",
            "processed mulyosyahidin/spring-boot-vocasia-microservices\n",
            "processed glific/k6io\n",
            "processed glific/k6io\n",
            "processed SamikshyaS/loadTest\n",
            "processed SamikshyaS/loadTest\n",
            "processed lelold/pvz\n",
            "processed lelold/pvz\n",
            "processed JonathanGunawan30/belajar-k6\n",
            "processed JonathanGunawan30/belajar-k6\n",
            "processed meownguyen1104/PerformanceTest\n",
            "processed meownguyen1104/PerformanceTest\n",
            "processed zapier/prom-aggregation-gateway\n",
            "processed zapier/prom-aggregation-gateway\n",
            "processed getBlackBadge/3rd-concert\n",
            "processed getBlackBadge/3rd-concert\n",
            "processed hr-rfp55-sdc2-cucco/Project-Atelier-Reviews-API\n",
            "processed hr-rfp55-sdc2-cucco/Project-Atelier-Reviews-API\n",
            "processed DFE-Digital/publish-teacher-training\n",
            "processed DFE-Digital/publish-teacher-training\n",
            "processed spryker/commerce-k6-performance-tests\n",
            "processed spryker/commerce-k6-performance-tests\n",
            "Clone timed out for logsk85-wq/iagentic. Skipping.\n",
            "Clone timed out for logsk85-wq/iagentic. Skipping.\n",
            "processed J-reyes132/api-test-k6\n",
            "processed J-reyes132/api-test-k6\n",
            "processed mmazune/chefcloud\n",
            "processed mmazune/chefcloud\n",
            "processed Arch-Frost/Tripify\n",
            "processed Arch-Frost/Tripify\n",
            "processed saiya/dsps\n",
            "processed saiya/dsps\n",
            "processed carloosbaquero/Cliente-TFM\n",
            "processed carloosbaquero/Cliente-TFM\n",
            "processed Boavizta/ecobenchmark-applicationweb-backend\n",
            "processed Boavizta/ecobenchmark-applicationweb-backend\n",
            "processed TelenorNorway/docker-for-win-issue-8861\n",
            "processed vfarcic/groundcover-demo\n",
            "processed TelenorNorway/docker-for-win-issue-8861\n",
            "processed vfarcic/groundcover-demo\n",
            "processed cristianlopera24/PetStore_Performance\n",
            "processed cristianlopera24/PetStore_Performance\n",
            "processed Zaha250/rg-testing\n",
            "processed Zaha250/rg-testing\n",
            "processed Dmitry-Boyko/Udemy\n",
            "processed Dmitry-Boyko/Udemy\n",
            "processed carlaferrarez/poc-istio-envoyfilter\n",
            "processed mountebank-testing/mountebank\n",
            "processed carlaferrarez/poc-istio-envoyfilter\n",
            "processed mountebank-testing/mountebank\n",
            "processed leo-badell/K6-course\n",
            "processed leo-badell/K6-course\n",
            "processed shardie-github/floyo\n",
            "processed shardie-github/floyo\n",
            "processed PurpleFishh/muzici\n",
            "processed PurpleFishh/muzici\n",
            "processed ydarias/xk6-nats\n",
            "processed ydarias/xk6-nats\n",
            "Clone timed out for Dmitriihub/studyproject2. Skipping.\n",
            "Clone timed out for Dmitriihub/studyproject2. Skipping.\n",
            "processed triszt4n/streamzen-monorepo\n",
            "processed triszt4n/streamzen-monorepo\n",
            "processed ham2k/lib-callsigns\n",
            "processed ham2k/lib-callsigns\n",
            "processed pleasebelieveme/merong\n",
            "processed pleasebelieveme/merong\n",
            "processed ohsu-comp-bio/load-testing\n",
            "processed afiffahreza/online-AutoLog\n",
            "processed ohsu-comp-bio/load-testing\n",
            "processed afiffahreza/online-AutoLog\n",
            "processed overist/hhd-plus-e-commerce\n",
            "processed overist/hhd-plus-e-commerce\n",
            "processed eswaryalakanti/Learning-Management-system\n",
            "processed eswaryalakanti/Learning-Management-system\n",
            "processed Magnificent-Malasada/productOverview\n",
            "processed Magnificent-Malasada/productOverview\n",
            "processed dikyayodihamzah/Load-Test\n",
            "processed van1164/AllYouRaffle-BE\n",
            "processed dikyayodihamzah/Load-Test\n",
            "processed van1164/AllYouRaffle-BE\n",
            "processed beatrizfteixeira/performance-mvc-webflux\n",
            "processed beatrizfteixeira/performance-mvc-webflux\n",
            "processed ququiz/scalable-ququiz-kubernetes\n",
            "processed ququiz/scalable-ququiz-kubernetes\n",
            "processed CarnegieMellon-PlantD/PlantD-operator\n",
            "processed Challe-P/report-load-tests\n",
            "processed CarnegieMellon-PlantD/PlantD-operator\n",
            "processed Challe-P/report-load-tests\n",
            "processed steadybit/examples\n",
            "processed steadybit/examples\n",
            "processed ChervyachokMigo/osu-tools\n",
            "processed ChervyachokMigo/osu-tools\n",
            "processed fernandoescolar/xk6-azservicebus\n",
            "processed fernandoescolar/xk6-azservicebus\n",
            "processed SDC8-Aragorn/Q-A\n",
            "processed SDC8-Aragorn/Q-A\n",
            "processed NelsonBN/samples-k6-tests\n",
            "processed NelsonBN/samples-k6-tests\n",
            "processed TomWang22/record-platform\n",
            "processed TomWang22/record-platform\n",
            "processed AratKruglik/octane-tests\n",
            "processed AratKruglik/octane-tests\n",
            "processed com-junkawasaki/fcdb\n",
            "processed Napat/k6_loadtest\n",
            "processed com-junkawasaki/fcdb\n",
            "processed Napat/k6_loadtest\n",
            "processed RayLiu1999/chat_app_backend\n",
            "processed RayLiu1999/chat_app_backend\n",
            "processed Consensys/codefi-assets-and-payments\n",
            "processed Consensys/codefi-assets-and-payments\n",
            "processed gpiechnik2/k6-boilerplate\n",
            "processed gpiechnik2/k6-boilerplate\n",
            "processed Milla2000/Shopify\n",
            "processed Milla2000/Shopify\n",
            "processed Hanumansai72/Backend\n",
            "processed Hanumansai72/Backend\n",
            "processed steverzag/result-pattern-exception-handling-demo\n",
            "processed steverzag/result-pattern-exception-handling-demo\n",
            "processed ruvnet/ruvector\n",
            "processed ruvnet/ruvector\n",
            "processed CrisDev2509/Sistema-Web-Hamburgueseria\n",
            "processed CrisDev2509/Sistema-Web-Hamburgueseria\n",
            "processed tmc/the-AIvengers\n",
            "processed tmc/the-AIvengers\n",
            "processed rpp36-sdc-smtp/smtp-othniel-reviews\n",
            "processed rpp36-sdc-smtp/smtp-othniel-reviews\n",
            "processed KakoF/Template_Distributed_Arch\n",
            "processed KakoF/Template_Distributed_Arch\n",
            "processed Meldiron/appwrite-functions-benchmark\n",
            "processed Meldiron/appwrite-functions-benchmark\n",
            "processed WizziGameDev/k6-performance-testing\n",
            "processed WizziGameDev/k6-performance-testing\n",
            "processed saimanikumar67/k6_scripts_testing\n",
            "processed saimanikumar67/k6_scripts_testing\n",
            "processed TestriqQA-Lab/testrq-3.0\n",
            "processed TestriqQA-Lab/testrq-3.0\n",
            "processed Abhay2412/SENG533FinalProject\n",
            "processed Abhay2412/SENG533FinalProject\n",
            "processed JS-Ranker/Monitoreo_k6\n",
            "processed JS-Ranker/Monitoreo_k6\n",
            "processed SolidMaster568/voluntarily-mern\n",
            "processed ViktorNovak1/DBI-Projekt-5DHIF-Wintersemester-Novak-Gregorich\n",
            "processed SolidMaster568/voluntarily-mern\n",
            "processed ViktorNovak1/DBI-Projekt-5DHIF-Wintersemester-Novak-Gregorich\n",
            "processed dongnguyenduybang/k6-report\n",
            "processed dongnguyenduybang/k6-report\n",
            "processed robersonliou/k6-playground\n",
            "processed robersonliou/k6-playground\n",
            "processed vini2sousa/banking-process\n",
            "processed vini2sousa/banking-process\n",
            "processed KontonGu/MLPerf-Inference-Benchmark-FaST-GShare\n",
            "processed KontonGu/MLPerf-Inference-Benchmark-FaST-GShare\n",
            "processed yoandiny/manasoa-education-backend\n",
            "processed yoandiny/manasoa-education-backend\n",
            "processed team-kutner/photo_carousel-service\n",
            "processed team-kutner/photo_carousel-service\n",
            "processed HappyPathsOnly/k6-more-examples\n",
            "processed HappyPathsOnly/k6-more-examples\n",
            "processed rfigueroa21/Laboratorio3\n",
            "processed rfigueroa21/Laboratorio3\n",
            "processed keith-liu-seagull-com/codeceptJS-KeithTest\n",
            "processed keith-liu-seagull-com/codeceptJS-KeithTest\n",
            "Clone timed out for zitadel/zitadel. Skipping.\n",
            "Clone timed out for zitadel/zitadel. Skipping.\n",
            "processed pcristin/not_golang_contest\n",
            "processed pcristin/not_golang_contest\n",
            "processed lucifer3618/next-dev\n",
            "processed lucifer3618/next-dev\n",
            "processed sidharthv96/tambola\n",
            "processed sidharthv96/tambola\n",
            "processed rpp36-sdc-smtp/smtp-serena-QnA\n",
            "processed rpp36-sdc-smtp/smtp-serena-QnA\n",
            "processed Informatievlaanderen/registry-testing\n",
            "processed Informatievlaanderen/registry-testing\n",
            "processed kyourselfer/OTUS_SRE202207\n",
            "processed kyourselfer/OTUS_SRE202207\n",
            "processed hanghae-plus-5th/hhplus-e-commerce\n",
            "processed hanghae-plus-5th/hhplus-e-commerce\n",
            "processed pagopa/pn-load-test\n",
            "processed pagopa/pn-load-test\n",
            "processed DishaKhilari/LeonardoAi\n",
            "processed DishaKhilari/LeonardoAi\n",
            "processed nexoqa/nexoqa_training_eng_adv_k6\n",
            "processed nexoqa/nexoqa_training_eng_adv_k6\n",
            "processed sharisroy/K6Learnign\n",
            "processed sharisroy/K6Learnign\n",
            "processed wy8162/study-ktor\n",
            "processed wy8162/study-ktor\n",
            "processed tianling0625/W255repo\n",
            "processed tianling0625/W255repo\n",
            "processed al03022140/devops-web-app\n",
            "processed al03022140/devops-web-app\n",
            "processed GiveMeAjob-job/Keycloak\n",
            "processed GiveMeAjob-job/Keycloak\n",
            "processed Matrics-io/k6-sdk\n",
            "processed Matrics-io/k6-sdk\n",
            "processed hr-rfp55-sdc2-cucco/questions-answers-endpoint\n",
            "processed hr-rfp55-sdc2-cucco/questions-answers-endpoint\n",
            "processed pryzmian/ScuttleCrab\n",
            "processed pryzmian/ScuttleCrab\n",
            "processed tomkaith13/session-based-dataprocessing\n",
            "processed tomkaith13/session-based-dataprocessing\n",
            "processed GyanaprakashKhandual/Automation-Functional-Py-Test\n",
            "processed GyanaprakashKhandual/Automation-Functional-Py-Test\n",
            "processed mpowrd/SoftwareMaintenanceAndTesting\n",
            "processed mpowrd/SoftwareMaintenanceAndTesting\n",
            "processed adi-testing/k6-performance-tests\n",
            "processed adi-testing/k6-performance-tests\n",
            "processed wisehero/hhplus-ecommerce\n",
            "processed wisehero/hhplus-ecommerce\n",
            "processed grafana/xk6-output-example\n",
            "processed grafana/xk6-output-example\n",
            "processed cortezalberto/pruebaMar\n",
            "processed cortezalberto/pruebaMar\n",
            "processed PacktPublishing/Implementing-Event-Driven-Architecture-in-.NET-5\n",
            "processed PacktPublishing/Implementing-Event-Driven-Architecture-in-.NET-5\n",
            "processed wayter95/benchmarks-monotlito-microservices\n",
            "processed wayter95/benchmarks-monotlito-microservices\n",
            "processed justLxy/PointPulse\n",
            "processed byounghoon95/concert-ticketing\n",
            "processed justLxy/PointPulse\n",
            "processed byounghoon95/concert-ticketing\n",
            "processed vfarcic/keda-demo\n",
            "processed vfarcic/keda-demo\n",
            "processed qcoop918/k6-bookstore-tests\n",
            "processed qcoop918/k6-bookstore-tests\n",
            "processed Hyperspace-Metaverse/xk6-socketio\n",
            "processed Hyperspace-Metaverse/xk6-socketio\n",
            "processed UrumiAI/wc-perf-testing\n",
            "processed UrumiAI/wc-perf-testing\n",
            "processed kwishna/Grafana-K6-performance-test\n",
            "processed kwishna/Grafana-K6-performance-test\n",
            "processed dhalexkim/k6-demo\n",
            "processed dhalexkim/k6-demo\n",
            "processed Parallels/prl-devops-service\n",
            "processed Parallels/prl-devops-service\n",
            "processed GHesericsu/cloudStay-PhotoGallery\n",
            "processed GHesericsu/cloudStay-PhotoGallery\n",
            "processed snothub/snothub.github.io\n",
            "processed snothub/snothub.github.io\n",
            "processed biancabelea/Mentum\n",
            "processed biancabelea/Mentum\n",
            "processed SwissLife-OSS/K6-MultiScenario-template\n",
            "processed SwissLife-OSS/K6-MultiScenario-template\n",
            "processed WhrTvT/hhplus-Ecommerce\n",
            "processed WhrTvT/hhplus-Ecommerce\n",
            "processed yangahh/concert-ticket-reservation\n",
            "processed yangahh/concert-ticket-reservation\n",
            "processed SungHo4119/eCommerce\n",
            "processed SungHo4119/eCommerce\n",
            "processed brodo/kubectl-k6\n",
            "processed brodo/kubectl-k6\n",
            "processed ren-joey/NestJS_dogcatstar\n",
            "processed ren-joey/NestJS_dogcatstar\n",
            "processed thetkpark/cscms-services-deployment\n",
            "processed thetkpark/cscms-services-deployment\n",
            "processed aotearoan/neon\n",
            "processed aotearoan/neon\n",
            "processed sipe-team/3-1_spurt\n",
            "processed sipe-team/3-1_spurt\n",
            "processed teri0411/Real-time-data-with-serverless\n",
            "processed teri0411/Real-time-data-with-serverless\n",
            "processed HuaHsuan-Liang/ScaleableResourceForDocker\n",
            "processed HuaHsuan-Liang/ScaleableResourceForDocker\n",
            "processed jimmyhogerty/Project-Ecom\n",
            "processed jimmyhogerty/Project-Ecom\n",
            "processed sheikhshack/openrainbow-poc-50.003\n",
            "processed jwcastillo/0_to_100_k6\n",
            "processed sheikhshack/openrainbow-poc-50.003\n",
            "processed jwcastillo/0_to_100_k6\n",
            "processed PedroCoelho8/QSOFT-Projeto\n",
            "processed PedroCoelho8/QSOFT-Projeto\n",
            "processed venuthomas/API_7_Ways\n",
            "processed venuthomas/API_7_Ways\n",
            "processed criscarlolm/k6-kubernetes-aws-loadtest\n",
            "processed criscarlolm/k6-kubernetes-aws-loadtest\n",
            "processed bamlab/performance-monitoring\n",
            "processed bamlab/performance-monitoring\n",
            "processed VladisSuh/StartupPCConfigurator\n",
            "processed VladisSuh/StartupPCConfigurator\n",
            "processed LUCASCNASC/k6-petstore\n",
            "processed Themba47622/k6-load-testing-example\n",
            "processed LUCASCNASC/k6-petstore\n",
            "processed Themba47622/k6-load-testing-example\n",
            "processed vunetsystems/Load-Testing-Tool\n",
            "processed vunetsystems/Load-Testing-Tool\n",
            "processed CHOHYUNHWA/concert-reservation-service\n",
            "processed CHOHYUNHWA/concert-reservation-service\n",
            "processed sf1tzp/symbology\n",
            "processed sf1tzp/symbology\n",
            "processed vitingr/educational-api\n",
            "processed vitingr/educational-api\n",
            "processed mitelute/10-40\n",
            "processed mitelute/10-40\n",
            "processed eixfix/smcc-load-test\n",
            "processed lucasonzta/deznity-core\n",
            "processed joergstreeck/freshplan-sales-tool\n",
            "processed eixfix/smcc-load-test\n",
            "processed lucasonzta/deznity-core\n",
            "processed joergstreeck/freshplan-sales-tool\n",
            "processed KMGeon/hhplus-e-commerce\n",
            "processed KMGeon/hhplus-e-commerce\n",
            "processed opencloud-eu/cdperf\n",
            "processed opencloud-eu/cdperf\n",
            "processed hoangnm-ndm/dummyjson\n",
            "processed hoangnm-ndm/dummyjson\n",
            "processed madhurendra1/DummyJSON\n",
            "processed madhurendra1/DummyJSON\n",
            "processed carlbray/mountebank\n",
            "processed carlbray/mountebank\n",
            "processed ibnc/mountebankMongo\n",
            "processed ibnc/mountebankMongo\n",
            "processed skgmfbs/ItHink\n",
            "processed skgmfbs/ItHink\n",
            "processed ngatiamwai/Shoppie\n",
            "Clone timed out for agussyahrilmubarok/course-assignments. Skipping.\n",
            "processed ngatiamwai/Shoppie\n",
            "Clone timed out for agussyahrilmubarok/course-assignments. Skipping.\n",
            "Clone timed out for farhanlabib/xk6-file-sample-project. Skipping.\n",
            "Clone timed out for farhanlabib/xk6-file-sample-project. Skipping.\n",
            "processed tmc/d2labs\n",
            "processed tmc/d2labs\n",
            "processed marlo2222/curso-teste-performance-k6\n",
            "processed marlo2222/curso-teste-performance-k6\n",
            "processed thiagoluzia/CursoK6.\n",
            "processed thiagoluzia/CursoK6.\n",
            "processed tonnarruda/k6_performanceTesting\n",
            "processed tonnarruda/k6_performanceTesting\n",
            "processed LariGTonetto/QAm28\n",
            "processed LariGTonetto/QAm28\n",
            "processed tmc/hackathon-starter\n",
            "processed tmc/hackathon-starter\n",
            "processed inspire12/performance-testing-architecture\n",
            "processed inspire12/performance-testing-architecture\n",
            "processed bcwilsondotcom/nx-monorepo-template\n",
            "processed bcwilsondotcom/nx-monorepo-template\n",
            "processed RustTest/wavReader\n",
            "processed RustTest/wavReader\n",
            "processed KontonGu/HAS-GPU\n",
            "processed KontonGu/HAS-GPU\n",
            "processed lakhyakotnala/ipython\n",
            "processed lakhyakotnala/ipython\n",
            "processed 23navi/k6\n",
            "processed 23navi/k6\n",
            "processed rkhokhla/kakeya\n",
            "processed rkhokhla/kakeya\n",
            "processed bcgov/healthgateway\n",
            "processed bcgov/healthgateway\n",
            "processed buildfarm/buildfarm\n",
            "processed buildfarm/buildfarm\n",
            "processed notmattpress/poocommerce\n",
            "processed notmattpress/poocommerce\n",
            "processed woocommerce/woocommerce\n",
            "processed woocommerce/woocommerce\n",
            "processed UrumiAI/starshop\n",
            "processed UrumiAI/starshop\n",
            "processed salvadalba/nodaysidle-website\n",
            "processed salvadalba/nodaysidle-website\n",
            "Clone timed out for Guspex/EBAC-QA. Skipping.\n",
            "Clone timed out for Guspex/EBAC-QA. Skipping.\n",
            "processed keboola/keboola-as-code\n",
            "processed keboola/keboola-as-code\n",
            "processed arnonsang/shadow-ua\n",
            "processed arnonsang/shadow-ua\n",
            "processed Umbra-Team/Umbra\n",
            "processed Umbra-Team/Umbra\n",
            "processed ApdexOne/grafana-prometheus\n",
            "processed ApdexOne/grafana-prometheus\n",
            "processed Salonee-Jain/k6\n",
            "processed Salonee-Jain/k6\n",
            "processed RafaelFerSilva/k6\n",
            "processed RafaelFerSilva/k6\n",
            "processed s00d/nuxt-i18n-micro\n",
            "processed s00d/nuxt-i18n-micro\n",
            "processed duyhuynh14/vendure\n",
            "processed duyhuynh14/vendure\n",
            "processed data-bass/Malcolm-SpotifyAlbum\n",
            "processed data-bass/Malcolm-SpotifyAlbum\n",
            "processed edusoftpro/js-k6\n",
            "processed edusoftpro/js-k6\n",
            "processed janzolini/k6-performance-test\n",
            "processed voluntarily/vly2\n",
            "processed janzolini/k6-performance-test\n",
            "processed voluntarily/vly2\n",
            "processed hyperledger-labs/splice\n",
            "processed hyperledger-labs/splice\n",
            "processed rpp36-sdc-bit/rpp36-chris-overview\n",
            "processed rpp36-sdc-bit/rpp36-chris-overview\n",
            "processed sivaprkolli/k6_sample_tests\n",
            "processed sivaprkolli/k6_sample_tests\n",
            "processed vicvalicelle/quality-assurance\n",
            "processed vicvalicelle/quality-assurance\n",
            "processed jyasuu/rs-benchmark\n",
            "processed jyasuu/rs-benchmark\n",
            "processed Kong/kong_ai_gateway-portkey-litellm-benchmark\n",
            "processed Kong/kong_ai_gateway-portkey-litellm-benchmark\n",
            "processed beincom/bic-notification-perf-load\n",
            "processed beincom/bic-notification-perf-load\n",
            "processed govuk-one-login/performance-testing\n",
            "processed govuk-one-login/performance-testing\n",
            "processed weaviate/xk6-weaviate\n",
            "processed weaviate/xk6-weaviate\n",
            "processed rafaelhbrasil/csharp_async_examples\n",
            "processed rafaelhbrasil/csharp_async_examples\n",
            "processed CanAISolutions/canai-cursor-codex-v6.1.4\n",
            "processed CanAISolutions/canai-cursor-codex-v6.1.4\n",
            "processed ekacs/K6-script-collection\n",
            "processed ekacs/K6-script-collection\n",
            "processed pwllxqc/amelichka\n",
            "processed pwllxqc/amelichka\n",
            "processed lgjsherond/TechHubDemo\n",
            "processed lgjsherond/TechHubDemo\n",
            "processed getcord/cord\n",
            "processed getcord/cord\n",
            "processed igorbrandao18/watch-test-backend\n",
            "processed igorbrandao18/watch-test-backend\n",
            "processed vimthelights/calculator\n",
            "processed vimthelights/calculator\n",
            "processed HeyCW/akademi-koding-performance-testing\n",
            "processed HeyCW/akademi-koding-performance-testing\n",
            "processed Gapminder/small-waffle\n",
            "processed Gapminder/small-waffle\n",
            "processed ruanbekker/grafana-observability-primer\n",
            "processed ruanbekker/grafana-observability-primer\n",
            "processed zidane-itb/APKS\n",
            "processed zidane-itb/APKS\n",
            "processed joanlopez/xk6-aws\n",
            "processed joanlopez/xk6-aws\n",
            "processed wizenheimer/periscope\n",
            "processed wizenheimer/periscope\n",
            "processed FalkFlow/api-php\n",
            "processed FalkFlow/api-php\n",
            "Clone timed out for wildananugrah/belajar. Skipping.\n",
            "Clone timed out for wildananugrah/belajar. Skipping.\n",
            "processed metasfresh/metasfresh\n",
            "processed metasfresh/metasfresh\n",
            "processed ducnt114/go-getting-started\n",
            "processed ducnt114/go-getting-started\n",
            "processed ONLYOFFICE/DocSpace-stress-tests\n",
            "processed ONLYOFFICE/DocSpace-stress-tests\n",
            "processed arn-ob/script-load-testing\n",
            "processed arn-ob/script-load-testing\n",
            "processed S6-LT/LumbridgeTimes\n",
            "processed S6-LT/LumbridgeTimes\n",
            "processed stellio-hub/ngsild-load-tests\n",
            "processed stellio-hub/ngsild-load-tests\n",
            "processed EscolaDnc/TesteEstabilidade\n",
            "processed EscolaDnc/TesteEstabilidade\n",
            "processed fishperson113/ticklab-challenge\n",
            "processed Qwitter/Qwitter-Testing\n",
            "processed fishperson113/ticklab-challenge\n",
            "processed Qwitter/Qwitter-Testing\n",
            "processed born-to-be-mad/azure-experiments\n",
            "processed born-to-be-mad/azure-experiments\n",
            "processed CryptoJym/ai-agent-village-monitor\n",
            "processed CryptoJym/ai-agent-village-monitor\n",
            "processed pdellaert/fbw-aircraft-git-lfs\n",
            "processed pdellaert/fbw-aircraft-git-lfs\n",
            "processed saint1991/samples\n",
            "processed saint1991/samples\n",
            "processed ozontech/seq-db\n",
            "processed ozontech/seq-db\n",
            "processed izhigalko/otus-demo-istio\n",
            "processed izhigalko/otus-demo-istio\n",
            "processed lemonson03/load-test-template\n",
            "processed lemonson03/load-test-template\n",
            "processed cabinetoffice/GCGS-Central-Digital-Platform\n",
            "processed cabinetoffice/GCGS-Central-Digital-Platform\n",
            "processed rogatka/advertisements\n",
            "processed rogatka/advertisements\n",
            "processed RavinduWeerakoon/front\n",
            "processed RavinduWeerakoon/front\n",
            "processed nadiaalnd/Performance-Test-Adameds-V3\n",
            "processed nadiaalnd/Performance-Test-Adameds-V3\n",
            "processed ignacioSuay/cloud-sql-performance-tests\n",
            "processed ignacioSuay/cloud-sql-performance-tests\n",
            "processed Krithikeswaranmk/final_helyxon\n",
            "processed Krithikeswaranmk/final_helyxon\n",
            "processed torbendury/kube-networkpolicy-denier\n",
            "processed torbendury/kube-networkpolicy-denier\n",
            "processed kithekadk/Employee-management-system\n",
            "processed kithekadk/Employee-management-system\n",
            "processed azophy/loadtest-tools-benchmark\n",
            "processed azophy/loadtest-tools-benchmark\n",
            "processed philipheferreira/Curso-teste-performance-com-K6\n",
            "processed philipheferreira/Curso-teste-performance-com-K6\n",
            "processed pgj/couchdb-k6\n",
            "processed pgj/couchdb-k6\n",
            "processed algotouch/algotouch-app\n",
            "Clone timed out for MateusNeres26/EBAC-QA. Skipping.\n",
            "processed algotouch/algotouch-app\n",
            "Clone timed out for MateusNeres26/EBAC-QA. Skipping.\n",
            "processed hitansh-tria/LoadTesting\n",
            "processed hitansh-tria/LoadTesting\n",
            "processed elrison/teste-desempenho-teastore\n",
            "processed jihadelsayed/Neetechs_Chain\n",
            "processed elrison/teste-desempenho-teastore\n",
            "processed jihadelsayed/Neetechs_Chain\n",
            "processed jsvitorm/ponderadasemana9m9\n",
            "processed jsvitorm/ponderadasemana9m9\n",
            "processed algonacci/k6-demo\n",
            "processed jpandof/sinfon-ia\n",
            "processed algonacci/k6-demo\n",
            "processed jpandof/sinfon-ia\n",
            "processed marcosborges/terraform-aws-loadtest-distribuited\n",
            "processed marcosborges/terraform-aws-loadtest-distribuited\n",
            "processed cognoco/User-Mgmt\n",
            "processed cognoco/User-Mgmt\n",
            "processed yunhalee05/walkerholic\n",
            "processed yunhalee05/walkerholic\n",
            "processed thomas-chiang/k6_sharing\n",
            "processed thomas-chiang/k6_sharing\n",
            "processed aziemp66/learn-k6\n",
            "processed aziemp66/learn-k6\n",
            "processed JavierSpartan-117/SQA_Semana_9\n",
            "processed JavierSpartan-117/SQA_Semana_9\n",
            "processed olgaStadnyk/k6-learning\n",
            "processed olgaStadnyk/k6-learning\n",
            "processed laszlo-igaz-ah/cloudx-java-developer\n",
            "processed laszlo-igaz-ah/cloudx-java-developer\n",
            "processed 576576/hadesbot-lite\n",
            "processed 576576/hadesbot-lite\n",
            "processed JoaoChoma/testedesoftware2025\n",
            "processed JoaoChoma/testedesoftware2025\n",
            "processed CrispinManda/Talky-the-Project.\n",
            "processed CrispinManda/Talky-the-Project.\n",
            "processed RemoteState/load-testing-tutorial\n",
            "processed RemoteState/load-testing-tutorial\n",
            "processed shamir92/go-boilerplate\n",
            "processed DimDev/php-runtimes-benchmark\n",
            "processed shamir92/go-boilerplate\n",
            "processed DimDev/php-runtimes-benchmark\n",
            "processed janbraunsdorff/catan\n",
            "processed janbraunsdorff/catan\n",
            "processed firmansyah-github/quarkus-generated-test\n",
            "processed firmansyah-github/quarkus-generated-test\n",
            "processed mentalclear/k6-project\n",
            "processed mentalclear/k6-project\n",
            "processed col3name/balance-service\n",
            "processed col3name/balance-service\n",
            "processed arslanrao991/zzreal_worriors\n",
            "processed arslanrao991/zzreal_worriors\n",
            "processed lucasguerra12/AV3\n",
            "processed lucasguerra12/AV3\n",
            "processed tgskyline/performancetest-k6\n",
            "processed tgskyline/performancetest-k6\n",
            "processed habyyb/CD-AdvancedDigitalIQ\n",
            "processed habyyb/CD-AdvancedDigitalIQ\n",
            "processed yudas-programador/Pruebas-de-integracion\n",
            "processed yudas-programador/Pruebas-de-integracion\n",
            "processed truonghd113hd/testCI\n",
            "processed truonghd113hd/testCI\n",
            "processed lucasjct/k6-udemy\n",
            "processed lucasjct/k6-udemy\n",
            "processed PraveenAsthana123/cypresstesting\n",
            "processed PraveenAsthana123/cypresstesting\n",
            "processed nyyshaaa/backend-app-complete\n",
            "processed nyyshaaa/backend-app-complete\n",
            "processed Ranj0z/Events-Ticketing-System\n",
            "processed Ranj0z/Events-Ticketing-System\n",
            "processed ronansay/next-web-app\n",
            "processed ronansay/next-web-app\n",
            "processed sourcegraph/k6\n",
            "processed sourcegraph/k6\n",
            "processed TheMech4nic/Multi_Vendor_Data_Fetch\n",
            "processed TheMech4nic/Multi_Vendor_Data_Fetch\n",
            "processed iago-abner/k6\n",
            "processed iago-abner/k6\n",
            "processed jeromeguillaume/kong-plugin-soap-xml-handling\n",
            "processed jeromeguillaume/kong-plugin-soap-xml-handling\n",
            "processed etalazz/vsa\n",
            "processed etalazz/vsa\n",
            "processed evc8p/gehtsoft-study\n",
            "processed evc8p/gehtsoft-study\n",
            "processed jeffascript/k6-load-testing\n",
            "processed jeffascript/k6-load-testing\n",
            "processed saifulazad/collections\n",
            "processed saifulazad/collections\n",
            "processed ToYou-Sparta/oddventure\n",
            "processed ToYou-Sparta/oddventure\n",
            "processed kimdh-hi/spring-study\n",
            "processed kimdh-hi/spring-study\n",
            "processed HellRok/jstris-companion\n",
            "processed HellRok/jstris-companion\n",
            "processed duongnv129/ory-self-hosted\n",
            "processed duongnv129/ory-self-hosted\n",
            "processed ethanshi2026/Dr_Lin_Class\n",
            "processed ethanshi2026/Dr_Lin_Class\n",
            "processed metrico/qryn-bench\n",
            "processed metrico/qryn-bench\n",
            "processed likesistemas/nginx\n",
            "processed likesistemas/nginx\n",
            "processed GualterAlbino/WebServiceK6\n",
            "processed GualterAlbino/WebServiceK6\n",
            "processed Spaceona/backend-go\n",
            "processed Spaceona/backend-go\n",
            "processed UKHO/exchange-set-service\n",
            "processed UKHO/exchange-set-service\n",
            "processed effectmoe/ai-accounting-system\n",
            "processed effectmoe/ai-accounting-system\n",
            "processed rpampin/elevate-ai-replit-modern\n",
            "processed rpampin/elevate-ai-replit-modern\n",
            "processed Timsl1401/Kosc-Spitsenspel\n",
            "processed Timsl1401/Kosc-Spitsenspel\n",
            "processed LukhasAI/Lukhas\n",
            "Finished processing all repositories. Collected data for 434 repositories.\n",
            "processed LukhasAI/Lukhas\n",
            "Finished processing all repositories. Collected data for 434 repositories.\n"
          ]
        }
      ],
      "source": [
        "# Parallelized cloning: clones multiple repos (shallow), counts lines, then removes clones\n",
        "import tempfile\n",
        "import shutil\n",
        "import subprocess\n",
        "import os\n",
        "import time\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# Configuration - ajuste conforme disponibilidade de rede / disco\n",
        "MAX_WORKERS = 8  # número de clones paralelos\n",
        "CLONE_TIMEOUT = 5*60  # segundos por clone\n",
        "\n",
        "repo_data = []\n",
        "\n",
        "def count_lines_in_tree(path):\n",
        "    \"\"\"Conta linhas em todos os arquivos do diretório `path`, ignorando arquivos binários e .git.\"\"\"\n",
        "    total = 0\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        # evitar entrar em .git\n",
        "        dirs[:] = [d for d in dirs if d != '.git']\n",
        "        for fname in files:\n",
        "            fpath = os.path.join(root, fname)\n",
        "            try:\n",
        "                # rápido teste binário: se contém null byte nos primeiros 1KB, pule\n",
        "                with open(fpath, 'rb') as fh:\n",
        "                    head = fh.read(1024)\n",
        "                    if b'\\x00' in head:\n",
        "                        continue\n",
        "                # contar quebras de linha em modo binário (eficiente)\n",
        "                count = 0\n",
        "                with open(fpath, 'rb') as fh:\n",
        "                    for chunk in iter(lambda: fh.read(8192), b''):\n",
        "                        count += chunk.count(b'\\n')\n",
        "                total += count\n",
        "            except Exception:\n",
        "                # ignora arquivos que não podem ser lidos\n",
        "                continue\n",
        "    return total\n",
        "\n",
        "\n",
        "def process_repo(repo_info):\n",
        "    \"\"\"Task para clonar um repositório via SSH, contar linhas e remover o clone.\"\"\"\n",
        "    repo_full_name = repo_info['repositório'] if isinstance(repo_info, dict) else repo_info\n",
        "    repo_url = repo_info.get('url') if isinstance(repo_info, dict) else None\n",
        "    owner, repo_name_only = repo_full_name.split('/')\n",
        "\n",
        "    result = {\n",
        "        'repositório': repo_full_name,\n",
        "        'url': repo_url,\n",
        "        'stargazers_count': 0,\n",
        "        'total_loc': 0,\n",
        "    }\n",
        "\n",
        "    details = get_repo_details(repo_full_name)\n",
        "    if not details:\n",
        "        print(f\"Could not get details for {repo_full_name}. Skipping.\")\n",
        "        return None\n",
        "    result['stargazers_count'] = details.get('stargazers_count', 0)\n",
        "\n",
        "    # SSH clone URL (requer chave SSH configurada)\n",
        "    clone_url = f'git@github.com:{owner}/{repo_name_only}.git'\n",
        "\n",
        "    tempdir = tempfile.mkdtemp(prefix='repo_clone_')\n",
        "    try:\n",
        "        # clonar shallow\n",
        "        subprocess.run(['git', 'clone', '--depth', '1', clone_url, tempdir], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, timeout=CLONE_TIMEOUT)\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(f\"Clone timed out for {repo_full_name}. Skipping.\")\n",
        "        try:\n",
        "            shutil.rmtree(tempdir)\n",
        "        except Exception:\n",
        "            pass\n",
        "        return None\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        # mostrar mensagem curta de erro\n",
        "        err = None\n",
        "        try:\n",
        "            err = e.stderr.decode('utf-8', errors='replace') if e.stderr else str(e)\n",
        "        except Exception:\n",
        "            err = str(e)\n",
        "        print(f\"git clone failed for {repo_full_name}: {err[:400]}. Skipping.\")\n",
        "        try:\n",
        "            shutil.rmtree(tempdir)\n",
        "        except Exception:\n",
        "            pass\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        loc = count_lines_in_tree(tempdir)\n",
        "        result['total_loc'] = loc\n",
        "    finally:\n",
        "        # cleanup sempre\n",
        "        try:\n",
        "            shutil.rmtree(tempdir)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    return result\n",
        "\n",
        "# Construir lista de repositórios preservando a URL do CSV\n",
        "repos_list = []\n",
        "for r in unique_repos:\n",
        "    if isinstance(r, dict):\n",
        "        repos_list.append({'repositório': r['repositório'], 'url': r.get('url')})\n",
        "    else:\n",
        "        repos_list.append({'repositório': r, 'url': None})\n",
        "\n",
        "print(f\"Starting parallel processing of {len(repos_list)} repositories with {MAX_WORKERS} workers...\")\n",
        "\n",
        "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "    future_to_repo = {executor.submit(process_repo, repo_info): repo_info['repositório'] for repo_info in repos_list}\n",
        "    for fut in as_completed(future_to_repo):\n",
        "        repo_name = future_to_repo[fut]\n",
        "        try:\n",
        "            res = fut.result()\n",
        "            if res:\n",
        "                print(f\"processed {res['repositório']}\")\n",
        "                repo_data.append(res)\n",
        "        except Exception as exc:\n",
        "            print(f\"Repository {repo_name} generated an exception: {exc}\")\n",
        "\n",
        "print(f\"Finished processing all repositories. Collected data for {len(repo_data)} repositories.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbbdb8d6",
        "outputId": "15d6602b-b828-422d-d85c-67dadfdbea54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed data saved to processed_k6_repos.csv\n",
            "(434, 4)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>repo</th>\n",
              "      <th>url</th>\n",
              "      <th>stars</th>\n",
              "      <th>loc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>adko99/loadtesting</td>\n",
              "      <td>https://github.com/adko99/loadtesting</td>\n",
              "      <td>0</td>\n",
              "      <td>1161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>grafana/k6-jslib-aws</td>\n",
              "      <td>https://github.com/grafana/k6-jslib-aws</td>\n",
              "      <td>24</td>\n",
              "      <td>9838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hari-p8-io/RestVsGrpc</td>\n",
              "      <td>https://github.com/hari-p8-io/RestVsGrpc</td>\n",
              "      <td>0</td>\n",
              "      <td>21572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HariSekhon/Templates</td>\n",
              "      <td>https://github.com/HariSekhon/Templates</td>\n",
              "      <td>164</td>\n",
              "      <td>20655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>grafana/setup-k6-action</td>\n",
              "      <td>https://github.com/grafana/setup-k6-action</td>\n",
              "      <td>18</td>\n",
              "      <td>39193</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      repo                                         url  stars  \\\n",
              "0       adko99/loadtesting       https://github.com/adko99/loadtesting      0   \n",
              "1     grafana/k6-jslib-aws     https://github.com/grafana/k6-jslib-aws     24   \n",
              "2    hari-p8-io/RestVsGrpc    https://github.com/hari-p8-io/RestVsGrpc      0   \n",
              "3     HariSekhon/Templates     https://github.com/HariSekhon/Templates    164   \n",
              "4  grafana/setup-k6-action  https://github.com/grafana/setup-k6-action     18   \n",
              "\n",
              "     loc  \n",
              "0   1161  \n",
              "1   9838  \n",
              "2  21572  \n",
              "3  20655  \n",
              "4  39193  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_processed_repos_limited = pd.DataFrame(repo_data)\n",
        "df_processed_repos_limited = df_processed_repos_limited.rename(columns={'repositório': 'repo', 'total_loc': 'loc', 'stargazers_count': 'stars', 'url': 'url'})\n",
        "\n",
        "df_processed_repos_limited.to_csv('processed_k6_repos.csv', index=False)\n",
        "\n",
        "print(\"Processed data saved to processed_k6_repos.csv\")\n",
        "print(df_processed_repos_limited.shape)\n",
        "df_processed_repos_limited.head()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv (3.14.0)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
