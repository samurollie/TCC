{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /home/samuel/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages (2.3.3)\n",
            "Requirement already satisfied: requests in /home/samuel/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages (2.32.5)\n",
            "Collecting dotenv\n",
            "  Using cached dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /home/samuel/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages (from pandas) (2.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/samuel/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/samuel/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/samuel/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/samuel/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/samuel/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/samuel/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/samuel/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages (from requests) (2025.11.12)\n",
            "Collecting python-dotenv (from dotenv)\n",
            "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: six>=1.5 in /home/samuel/Documentos/TCC/tests-TCC/venv/lib64/python3.14/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Using cached dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
            "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: python-dotenv, dotenv\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [dotenv]\n",
            "\u001b[1A\u001b[2KSuccessfully installed dotenv-0.9.9 python-dotenv-1.2.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas requests dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')\n",
        "\n",
        "if not GITHUB_TOKEN:\n",
        "    raise RuntimeError(\"GITHUB_TOKEN não encontrado no .env. Adicione uma linha: GITHUB_TOKEN=seu_token\")\n",
        "\n",
        "HEADERS = {'Authorization': f'token {GITHUB_TOKEN}'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gerar CSV pra usar na analise dos repositorios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdxvapkcKjsE",
        "outputId": "0011a504-328f-4dbd-d479-5f4271970b79"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import csv\n",
        "import time\n",
        "\n",
        "# Função para buscar repositórios, agora com debug e URL encoding\n",
        "def buscar_repositorios(paginas=5):\n",
        "    repositorios = {}\n",
        "    url = 'https://api.github.com/search/code'\n",
        "    query = 'import \"k6\" OR import \\'k6\\' language:JavaScript OR language:TypeScript'\n",
        "\n",
        "    for page in range(1, paginas + 1):\n",
        "        params = {'q': query, 'per_page': 100, 'page': page}\n",
        "        print(f'Buscando página {page} com query: {params[\"q\"]}')  # DEBUG\n",
        "        response = requests.get(url, headers=HEADERS, params=params)\n",
        "        print(f'Status code: {response.status_code}')  # DEBUG\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            if 'items' not in data or len(data['items']) == 0:\n",
        "                print(f'Nenhum resultado encontrado na página {page}. Encerrando busca.')\n",
        "                break\n",
        "            for item in data['items']:\n",
        "                repo_name = item['repository']['full_name']\n",
        "                repo_url = item['repository']['html_url']\n",
        "                file_path = item['path']\n",
        "                if repo_name not in repositorios:\n",
        "                    repositorios[repo_name] = {'url': repo_url, 'arquivos': []}\n",
        "                repositorios[repo_name]['arquivos'].append(file_path)\n",
        "        elif response.status_code == 403:\n",
        "            print(f'Limite de taxa atingido. Aguardando 60 segundos.')\n",
        "            time.sleep(60)\n",
        "            page -= 1  # Retry current page\n",
        "            continue\n",
        "        elif response.status_code == 422:\n",
        "            print(f'Erro 422 (Unprocessable Entity) na página {page}. Isso geralmente indica que o limite de 1000 resultados da API de busca do GitHub foi atingido ou a consulta é inválida. Encerrando busca.')\n",
        "            break  # Stop if we hit this error\n",
        "        else:\n",
        "            print(f'Erro inesperado na requisição na página {page}: {response.status_code}. Encerrando busca.')\n",
        "            break\n",
        "\n",
        "    return repositorios\n",
        "\n",
        "# Função para salvar CSV permanece igual\n",
        "def salvar_csv(repositorios, arquivo_saida='repositorios_k6.csv'):\n",
        "    with open(arquivo_saida, mode='w', newline='', encoding='utf-8') as csv_file:\n",
        "        fieldnames = ['repositório', 'url', 'arquivos']\n",
        "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for repo_name, info in repositorios.items():\n",
        "            writer.writerow({'repositório': repo_name, 'url': info['url'], 'arquivos': '; '.join(info['arquivos'])})\n",
        "    print(f'Resultados salvos em {arquivo_saida}')\n",
        "\n",
        "\n",
        "repositorios = buscar_repositorios(paginas=5)\n",
        "print(f'Total de repositórios encontrados: {len(repositorios)}')\n",
        "salvar_csv(repositorios)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gerar o CSV pra uso no TCC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "b9702ea8"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import base64\n",
        "import requests\n",
        "import csv\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Funções auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac8bb086",
        "outputId": "60951df3-e56a-45ec-c93b-005b30270ed9"
      },
      "outputs": [],
      "source": [
        "def make_github_api_request(url, params=None, max_retries=5):\n",
        "    for retry_num in range(max_retries):\n",
        "        try:\n",
        "            response = requests.get(url, headers=HEADERS, params=params)\n",
        "            if response.status_code == 200:\n",
        "                return response.json()\n",
        "            elif response.status_code == 403:\n",
        "                print(f\"Rate limit exceeded. Waiting 60 seconds. Retries left: {max_retries - 1 - retry_num}\")\n",
        "                time.sleep(60)\n",
        "            elif response.status_code == 404:\n",
        "                print(f\"Resource not found at {url}. Skipping.\")\n",
        "                return None\n",
        "            else:\n",
        "                print(f\"Error making request to {url}: Status code {response.status_code}, Response: {response.text}\")\n",
        "                return None\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Request failed: {e}. Retries left: {max_retries - 1 - retry_num}\")\n",
        "            time.sleep(5) # Shorter wait for network errors\n",
        "    print(f\"Failed to make request to {url} after {max_retries} retries.\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9fe5338",
        "outputId": "38c28647-e1c1-44e9-ef6b-a09b309df7e4"
      },
      "outputs": [],
      "source": [
        "def get_repo_details(repo_full_name):\n",
        "    owner, repo = repo_full_name.split('/')\n",
        "    url = f'https://api.github.com/repos/{owner}/{repo}'\n",
        "    repo_data = make_github_api_request(url)\n",
        "    if repo_data:\n",
        "        return {\n",
        "            'default_branch': repo_data.get('default_branch'),\n",
        "            'stargazers_count': repo_data.get('stargazers_count')\n",
        "        }\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6ecbcda",
        "outputId": "9dec8261-8660-497a-b7dc-b539cac8a298"
      },
      "outputs": [],
      "source": [
        "def get_file_tree(repo_full_name, sha):\n",
        "    owner, repo = repo_full_name.split('/')\n",
        "    url = f'https://api.github.com/repos/{owner}/{repo}/git/trees/{sha}?recursive=1'\n",
        "    tree_data = make_github_api_request(url)\n",
        "    if tree_data and 'tree' in tree_data:\n",
        "        non_markdown_files = []\n",
        "        markdown_extensions = ('.md', '.markdown')\n",
        "        for item in tree_data['tree']:\n",
        "            # Return path and sha for non-markdown blob files\n",
        "            if item['type'] == 'blob' and not item['path'].lower().endswith(markdown_extensions):\n",
        "                non_markdown_files.append({'path': item['path'], 'sha': item['sha']})\n",
        "        return non_markdown_files\n",
        "    return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40158aff",
        "outputId": "10036c3f-fdb6-4ec8-c268-0b6d2e1241da"
      },
      "outputs": [],
      "source": [
        "def get_file_content(repo_full_name, file_sha):\n",
        "    owner, repo = repo_full_name.split('/')\n",
        "    url = f'https://api.github.com/repos/{owner}/{repo}/git/blobs/{file_sha}'\n",
        "\n",
        "    blob_data = make_github_api_request(url)\n",
        "\n",
        "    if blob_data:\n",
        "        content_encoding = blob_data.get('encoding')\n",
        "        content_data = blob_data.get('content')\n",
        "\n",
        "        if content_data is None:\n",
        "            print(f\"No content data found for SHA {file_sha} in {repo_full_name}. Skipping.\")\n",
        "            return None\n",
        "\n",
        "        if content_encoding == 'base64':\n",
        "            try:\n",
        "                # Base64 decode, then try UTF-8 decode\n",
        "                decoded_bytes = base64.b64decode(content_data)\n",
        "                decoded_content = decoded_bytes.decode('utf-8')\n",
        "                return decoded_content\n",
        "            except UnicodeDecodeError:\n",
        "                print(f\"UnicodeDecodeError for SHA {file_sha} in {repo_full_name}. Content appears binary or non-UTF8. Skipping.\")\n",
        "                return None\n",
        "            except Exception as e:\n",
        "                print(f\"Error decoding base64 content for SHA {file_sha} in {repo_full_name}: {e}. Skipping.\")\n",
        "                return None\n",
        "        elif content_encoding == 'utf-8':\n",
        "            # Content is already UTF-8 encoded string\n",
        "            return content_data\n",
        "        else:\n",
        "            print(f\"Unknown or unsupported encoding '{content_encoding}' for SHA {file_sha} in {repo_full_name}. Skipping.\")\n",
        "            return None\n",
        "    elif blob_data is None:\n",
        "        # make_github_api_request already printed error/skip message\n",
        "        return None\n",
        "    else:\n",
        "        print(f\"Could not get blob data for SHA {file_sha} in {repo_full_name}. Skipping.\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31f33101",
        "outputId": "5339ff7a-5932-4ef4-8dea-91a106f4a6bc"
      },
      "outputs": [],
      "source": [
        "def count_lines_of_code(content):\n",
        "    if content is None:\n",
        "        return 0\n",
        "    return len(content.splitlines())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Obter os dados e salvar no csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6333a52",
        "outputId": "5663ba4d-83c0-4071-c0f6-89243152fce6"
      },
      "outputs": [],
      "source": [
        "df_repos = pd.read_csv('repositorios_k6.csv')\n",
        "unique_repos = df_repos[['repositório', 'url']].drop_duplicates().to_dict('records')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a184117",
        "outputId": "fb5966ed-947b-47c2-c97f-7eaa95fb83cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing repository: HariSekhon/Templates\n",
            "Processing repository: grafana/setup-k6-action\n",
            "UnicodeDecodeError for SHA 2a0941e524719b003da742ddee916477da4446a8 in grafana/setup-k6-action. Content appears binary or non-UTF8. Skipping.\n",
            "Finished processing all repositories. Collected data for 2 repositories.\n"
          ]
        }
      ],
      "source": [
        "repo_data = [] # Reset repo_data for processing all unique repositories\n",
        "\n",
        "# for repo_info in unique_repos: # Iterate through ALL unique repositories\n",
        "for repo_info in unique_repos[:2]: # Analisa so 2\n",
        "    repo_full_name = repo_info['repositório']\n",
        "    repo_url = repo_info['url']\n",
        "    owner, repo_name_only = repo_full_name.split('/')\n",
        "\n",
        "    print(f\"Processing repository: {repo_full_name}\")\n",
        "\n",
        "    details = get_repo_details(repo_full_name)\n",
        "    if not details:\n",
        "        print(f\"Could not get details for {repo_full_name}. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    default_branch = details['default_branch']\n",
        "    stargazers_count = details['stargazers_count']\n",
        "\n",
        "    # Get the SHA of the default branch's head commit\n",
        "    branch_url = f'https://api.github.com/repos/{owner}/{repo_name_only}/branches/{default_branch}'\n",
        "    branch_data = make_github_api_request(branch_url)\n",
        "    if not branch_data or 'commit' not in branch_data or 'sha' not in branch_data['commit']:\n",
        "        print(f\"Could not get default branch SHA for {repo_full_name}. Skipping.\")\n",
        "        continue\n",
        "    default_branch_sha = branch_data['commit']['sha']\n",
        "\n",
        "    # get_file_tree now returns dictionaries with 'path' and 'sha'\n",
        "    non_markdown_files = get_file_tree(repo_full_name, default_branch_sha)\n",
        "    if not non_markdown_files:\n",
        "        print(f\"No non-markdown files found or could not get file tree for {repo_full_name}. Skipping LOC counting.\")\n",
        "\n",
        "    total_loc = 0\n",
        "    for file_item in non_markdown_files:\n",
        "        # Pass file_sha to get_file_content\n",
        "        content = get_file_content(repo_full_name, file_item['sha'])\n",
        "        if content is not None:\n",
        "            total_loc += count_lines_of_code(content)\n",
        "\n",
        "    repo_data.append({\n",
        "        'repositório': repo_full_name,\n",
        "        'url': repo_url,\n",
        "        'stargazers_count': stargazers_count,\n",
        "        'total_loc': total_loc\n",
        "    })\n",
        "\n",
        "print(f\"Finished processing all repositories. Collected data for {len(repo_data)} repositories.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbbdb8d6",
        "outputId": "15d6602b-b828-422d-d85c-67dadfdbea54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed data saved to processed_k6_repos.csv\n",
            "                      repo                                         url  stars  \\\n",
            "0     HariSekhon/Templates     https://github.com/HariSekhon/Templates    164   \n",
            "1  grafana/setup-k6-action  https://github.com/grafana/setup-k6-action     18   \n",
            "\n",
            "     loc  \n",
            "0  14182  \n",
            "1  39109  \n"
          ]
        }
      ],
      "source": [
        "df_processed_repos_limited = pd.DataFrame(repo_data)\n",
        "df_processed_repos_limited = df_processed_repos_limited.rename(columns={'repositório': 'repo', 'total_loc': 'loc', 'stargazers_count': 'stars', 'url': 'url'})\n",
        "\n",
        "df_processed_repos_limited.to_csv('processed_k6_repos.csv', index=False)\n",
        "\n",
        "print(\"Processed data saved to processed_k6_repos.csv\")\n",
        "print(df_processed_repos_limited.head())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv (3.14.0)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
